{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dgcca_exampe.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V9N9qOflxBnN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXUnAAm9Cozo"
      },
      "source": [
        "# **An Exampe of Using the DGCCA Package - dgcca_pckg (Under Development)**\r\n",
        "An example of using the dgcca package to the 'Mushroom Classification' dataset (Source :https://www.kaggle.com/uciml/mushroom-classification) to classify mushrooms as 'edible' or 'poisonous'.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "**Dataset Description** - Cardiotocograms (CTGs) are a simple and cost accessible option to assess fetal health, allowing doctors to take action to prevent child and maternal mortality. This dataset includes 2126 records of features extracted from Cardiotocogram exams, which are classified into 3 classes: Normal, Suspect, Pathological.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "**Objective** - Create a multiclass model to classify CTG features into the three fetal health states.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "**Classification Models Used** -\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0qhLA2-EFJ0"
      },
      "source": [
        "!pip install cca-zoo"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO5dmPwzumlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bcd146a-784b-4f9d-c9ef-dfc3cedc1b2e"
      },
      "source": [
        "#Importing required libraries\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sn\r\n",
        "import io\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        " \r\n",
        "# import dgcca\r\n",
        "# !python dgcca.py"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "tkKEdx44wsku",
        "outputId": "5da28d9f-97e6-485a-eac8-a925b885ac83"
      },
      "source": [
        "#uploading GlobalTempratures.csv on Google Colab\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-32dea696-d8bf-4643-a698-a12521043500\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-32dea696-d8bf-4643-a698-a12521043500\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fetal_health.csv to fetal_health (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1F3rDW5honL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "593f1da5-5d53-4940-eb9d-f7c0a9d65498"
      },
      "source": [
        "#Reading Data\r\n",
        "data = pd.read_csv(io.BytesIO(uploaded['fetal_health.csv']))\r\n",
        "data.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline value</th>\n",
              "      <th>accelerations</th>\n",
              "      <th>fetal_movement</th>\n",
              "      <th>uterine_contractions</th>\n",
              "      <th>light_decelerations</th>\n",
              "      <th>severe_decelerations</th>\n",
              "      <th>prolongued_decelerations</th>\n",
              "      <th>abnormal_short_term_variability</th>\n",
              "      <th>mean_value_of_short_term_variability</th>\n",
              "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
              "      <th>mean_value_of_long_term_variability</th>\n",
              "      <th>histogram_width</th>\n",
              "      <th>histogram_min</th>\n",
              "      <th>histogram_max</th>\n",
              "      <th>histogram_number_of_peaks</th>\n",
              "      <th>histogram_number_of_zeroes</th>\n",
              "      <th>histogram_mode</th>\n",
              "      <th>histogram_mean</th>\n",
              "      <th>histogram_median</th>\n",
              "      <th>histogram_variance</th>\n",
              "      <th>histogram_tendency</th>\n",
              "      <th>fetal_health</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>43.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>64.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>132.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>130.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133.0</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>130.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134.0</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>132.0</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.9</td>\n",
              "      <td>117.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   baseline value  accelerations  ...  histogram_tendency  fetal_health\n",
              "0           120.0          0.000  ...                 1.0           2.0\n",
              "1           132.0          0.006  ...                 0.0           1.0\n",
              "2           133.0          0.003  ...                 0.0           1.0\n",
              "3           134.0          0.003  ...                 1.0           1.0\n",
              "4           132.0          0.007  ...                 1.0           1.0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoauR3fZCkIN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "7741d144-f7f3-44d6-9ef9-eb0987f977a9"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline value</th>\n",
              "      <th>accelerations</th>\n",
              "      <th>fetal_movement</th>\n",
              "      <th>uterine_contractions</th>\n",
              "      <th>light_decelerations</th>\n",
              "      <th>severe_decelerations</th>\n",
              "      <th>prolongued_decelerations</th>\n",
              "      <th>abnormal_short_term_variability</th>\n",
              "      <th>mean_value_of_short_term_variability</th>\n",
              "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
              "      <th>mean_value_of_long_term_variability</th>\n",
              "      <th>histogram_width</th>\n",
              "      <th>histogram_min</th>\n",
              "      <th>histogram_max</th>\n",
              "      <th>histogram_number_of_peaks</th>\n",
              "      <th>histogram_number_of_zeroes</th>\n",
              "      <th>histogram_mode</th>\n",
              "      <th>histogram_mean</th>\n",
              "      <th>histogram_median</th>\n",
              "      <th>histogram_variance</th>\n",
              "      <th>histogram_tendency</th>\n",
              "      <th>fetal_health</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.00000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>133.303857</td>\n",
              "      <td>0.003178</td>\n",
              "      <td>0.009481</td>\n",
              "      <td>0.004366</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>46.990122</td>\n",
              "      <td>1.332785</td>\n",
              "      <td>9.84666</td>\n",
              "      <td>8.187629</td>\n",
              "      <td>70.445908</td>\n",
              "      <td>93.579492</td>\n",
              "      <td>164.025400</td>\n",
              "      <td>4.068203</td>\n",
              "      <td>0.323612</td>\n",
              "      <td>137.452023</td>\n",
              "      <td>134.610536</td>\n",
              "      <td>138.090310</td>\n",
              "      <td>18.808090</td>\n",
              "      <td>0.320320</td>\n",
              "      <td>1.304327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.840844</td>\n",
              "      <td>0.003866</td>\n",
              "      <td>0.046666</td>\n",
              "      <td>0.002946</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>17.192814</td>\n",
              "      <td>0.883241</td>\n",
              "      <td>18.39688</td>\n",
              "      <td>5.628247</td>\n",
              "      <td>38.955693</td>\n",
              "      <td>29.560212</td>\n",
              "      <td>17.944183</td>\n",
              "      <td>2.949386</td>\n",
              "      <td>0.706059</td>\n",
              "      <td>16.381289</td>\n",
              "      <td>15.593596</td>\n",
              "      <td>14.466589</td>\n",
              "      <td>28.977636</td>\n",
              "      <td>0.610829</td>\n",
              "      <td>0.614377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>133.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>67.500000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>11.00000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>160.000000</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.481000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>91.00000</td>\n",
              "      <td>50.700000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>269.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       baseline value  accelerations  ...  histogram_tendency  fetal_health\n",
              "count     2126.000000    2126.000000  ...         2126.000000   2126.000000\n",
              "mean       133.303857       0.003178  ...            0.320320      1.304327\n",
              "std          9.840844       0.003866  ...            0.610829      0.614377\n",
              "min        106.000000       0.000000  ...           -1.000000      1.000000\n",
              "25%        126.000000       0.000000  ...            0.000000      1.000000\n",
              "50%        133.000000       0.002000  ...            0.000000      1.000000\n",
              "75%        140.000000       0.006000  ...            1.000000      1.000000\n",
              "max        160.000000       0.019000  ...            1.000000      3.000000\n",
              "\n",
              "[8 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJrPKqcgw9k4",
        "outputId": "7c457385-3f12-47cb-fab7-71eae397e886"
      },
      "source": [
        "data.info() \r\n",
        "#The dataset has no missing values"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2126 entries, 0 to 2125\n",
            "Data columns (total 22 columns):\n",
            " #   Column                                                  Non-Null Count  Dtype  \n",
            "---  ------                                                  --------------  -----  \n",
            " 0   baseline value                                          2126 non-null   float64\n",
            " 1   accelerations                                           2126 non-null   float64\n",
            " 2   fetal_movement                                          2126 non-null   float64\n",
            " 3   uterine_contractions                                    2126 non-null   float64\n",
            " 4   light_decelerations                                     2126 non-null   float64\n",
            " 5   severe_decelerations                                    2126 non-null   float64\n",
            " 6   prolongued_decelerations                                2126 non-null   float64\n",
            " 7   abnormal_short_term_variability                         2126 non-null   float64\n",
            " 8   mean_value_of_short_term_variability                    2126 non-null   float64\n",
            " 9   percentage_of_time_with_abnormal_long_term_variability  2126 non-null   float64\n",
            " 10  mean_value_of_long_term_variability                     2126 non-null   float64\n",
            " 11  histogram_width                                         2126 non-null   float64\n",
            " 12  histogram_min                                           2126 non-null   float64\n",
            " 13  histogram_max                                           2126 non-null   float64\n",
            " 14  histogram_number_of_peaks                               2126 non-null   float64\n",
            " 15  histogram_number_of_zeroes                              2126 non-null   float64\n",
            " 16  histogram_mode                                          2126 non-null   float64\n",
            " 17  histogram_mean                                          2126 non-null   float64\n",
            " 18  histogram_median                                        2126 non-null   float64\n",
            " 19  histogram_variance                                      2126 non-null   float64\n",
            " 20  histogram_tendency                                      2126 non-null   float64\n",
            " 21  fetal_health                                            2126 non-null   float64\n",
            "dtypes: float64(22)\n",
            "memory usage: 365.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jybVZAw8RUc3",
        "outputId": "28018f05-8b5c-452c-8ff9-04ab34f8ea7d"
      },
      "source": [
        "# counting no of unique values of each column\r\n",
        "for x in data.columns.array:\r\n",
        "  print(x, (data[x]).nunique()) "
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline value 48\n",
            "accelerations 20\n",
            "fetal_movement 102\n",
            "uterine_contractions 16\n",
            "light_decelerations 16\n",
            "severe_decelerations 2\n",
            "prolongued_decelerations 6\n",
            "abnormal_short_term_variability 75\n",
            "mean_value_of_short_term_variability 57\n",
            "percentage_of_time_with_abnormal_long_term_variability 87\n",
            "mean_value_of_long_term_variability 249\n",
            "histogram_width 154\n",
            "histogram_min 109\n",
            "histogram_max 86\n",
            "histogram_number_of_peaks 18\n",
            "histogram_number_of_zeroes 9\n",
            "histogram_mode 88\n",
            "histogram_mean 103\n",
            "histogram_median 95\n",
            "histogram_variance 133\n",
            "histogram_tendency 3\n",
            "fetal_health 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Necz5mroRe1D"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT2UuK5OALOF"
      },
      "source": [
        "## DGCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCJ1g3FAeUk"
      },
      "source": [
        "#importing required libraries -\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim \r\n",
        "from torch.utils.data import BatchSampler, SequentialSampler, RandomSampler\r\n",
        "from cca_zoo.objectives import GCCA as GCCA_Loss\r\n",
        "from cca_zoo.wrapper import Wrapper as GCCA\r\n",
        "#Loss() method takes the outputs of each view's network and solves the generalized CCA eigenproblem"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxkKliMPKRZn"
      },
      "source": [
        "class DNN(nn.Module):\r\n",
        "    def __init__(self, layer_size, activation):\r\n",
        "        super(DNN, self).__init__()\r\n",
        "        layers = []\r\n",
        "        self.activation = activation\r\n",
        "        \r\n",
        "        # Defaults to sigmoid \r\n",
        "        if self.activation == 'relu':\r\n",
        "          self.activation_func = nn.RelU()\r\n",
        "        elif self.activation == 'tanh':\r\n",
        "          self.activation_func = nn.Tanh()\r\n",
        "        elif self.activation == 'sigmoid':\r\n",
        "          self.activation_func = nn.Sigmoid()\r\n",
        "        else:\r\n",
        "          self.activation_func = nn.Sigmoid()\r\n",
        "\r\n",
        "        for l_id in range(len(layer_size) - 1):\r\n",
        "            if l_id == len(layer_size) - 2: #second last layer\r\n",
        "                layers.append(nn.Sequential(\r\n",
        "                    nn.BatchNorm1d(num_features=layer_size[l_id], affine=False),\r\n",
        "                    nn.Linear(layer_size[l_id], layer_size[l_id + 1]),\r\n",
        "                ))\r\n",
        "            else: #all other layers\r\n",
        "                layers.append(nn.Sequential(\r\n",
        "                    nn.Linear(layer_size[l_id], layer_size[l_id + 1]), \r\n",
        "                    self.activation_func,\r\n",
        "                    nn.BatchNorm1d(num_features=layer_size[l_id + 1], affine=False),                                     \r\n",
        "                ))\r\n",
        "\r\n",
        "        self.layers = nn.ModuleList(layers)\r\n",
        "\r\n",
        "    def forward(self, l):\r\n",
        "        for layer in self.layers:\r\n",
        "            l = layer(l)\r\n",
        "        return l"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBod0w7SNGQH"
      },
      "source": [
        "class DGCCA_architecture(nn.Module): # for three views\r\n",
        "    def __init__(self, layer_size1, layer_size2, layer_size3, activation):\r\n",
        "        super(DGCCA_architecture, self).__init__()\r\n",
        "        self.activation = activation\r\n",
        "        self.model1 = DNN(layer_sizes1,activation)\r\n",
        "        self.model2 = DNN(layer_sizes2,activation)\r\n",
        "        self.model3 = DNN(layer_sizes2,activation)\r\n",
        "\r\n",
        "    def forward(self, x1, x2, x3):\r\n",
        "        output1 = self.model1(x1)\r\n",
        "        output2 = self.model2(x2)\r\n",
        "        output3 = self.model3(x3)\r\n",
        "\r\n",
        "        return output1, output2, output3"
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET3gH4CSP7BQ"
      },
      "source": [
        "class DGCCA(nn.Module):\r\n",
        "  def __init__(self, architecture, learning_rate, epoch_num, batch_size, reg_par, out_size:int):\r\n",
        "        super(DGCCA, self).__init__()\r\n",
        "        self.arch = architecture\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.reg_par = reg_par\r\n",
        "        # Stochastic Gradient Descent used as optimizer like in the research paper\r\n",
        "        self.optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=reg_par)\r\n",
        "        self.epoch_num = epoch_num\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.out_size = out_size\r\n",
        "        # The GCCA loss function\r\n",
        "        self.loss_function = GCCA_Loss(self.out_size , self.reg_par).loss\r\n",
        "\r\n",
        "  def _get_outputs(self, x1, x2, x3):\r\n",
        "        with torch.no_grad():\r\n",
        "            self.arch.eval()\r\n",
        "            data_size = x1.size(0)\r\n",
        "            batch_idxs = list(BatchSampler(SequentialSampler(\r\n",
        "                range(data_size)), batch_size=self.batch_size, drop_last=False))\r\n",
        "            losses = []\r\n",
        "            outputs1 = []\r\n",
        "            outputs2 = []\r\n",
        "            outputs3 = []\r\n",
        "            for x in batch_idxs:\r\n",
        "                batch_x1 = x1[x, :]\r\n",
        "                batch_x2 = x2[x, :]\r\n",
        "                batch_x3 = x3[x, :]\r\n",
        "                o1, o2, o3 = self.arch(batch_x1, batch_x2, batch_x3)\r\n",
        "                outputs1.append(o1)\r\n",
        "                outputs2.append(o2)\r\n",
        "                outputs3.append(o3)\r\n",
        "                loss = self.loss_function(o1, o2, o3)\r\n",
        "                losses.append(loss.item())\r\n",
        "        outputs = [torch.cat(outputs1, dim=0).numpy(),\r\n",
        "                   torch.cat(outputs2, dim=0).numpy(),\r\n",
        "                   torch.cat(outputs3, dim=0).numpy()]\r\n",
        "        return losses, outputs\r\n",
        "\r\n",
        "  def test(self, x1, x2, x3):\r\n",
        "        with torch.no_grad():\r\n",
        "            losses, outputs = self._get_outputs(x1, x2, x3)\r\n",
        "            return np.mean(losses), outputs\r\n",
        "\r\n",
        "  def fit(self, train_x1, train_x2, train_x3, test_x1, test_x2, test_x3):\r\n",
        "      data_size = train_x1.size(0)\r\n",
        "      train_losses = []\r\n",
        "      for epoch in range(self.epoch_num):\r\n",
        "          self.arch.train()\r\n",
        "          batch_idxs = list(BatchSampler(RandomSampler(\r\n",
        "              range(data_size)), batch_size=self.batch_size, drop_last=False))\r\n",
        "          for x in batch_idxs:\r\n",
        "              self.optimizer.zero_grad()           \r\n",
        "              batch_x1 = train_x1[x, :]\r\n",
        "              batch_x2 = train_x2[x, :]\r\n",
        "              batch_x3 = train_x3[x, :] \r\n",
        "              o1, o2, o3 = self.arch(batch_x1, batch_x2, batch_x3)\r\n",
        "              loss = self.loss_function(o1, o2, o3)\r\n",
        "              train_losses.append(loss.data)\r\n",
        "              loss.backward()\r\n",
        "              self.optimizer.step()\r\n",
        "\r\n",
        "          # training the gcca model\r\n",
        "          _, outputs = self._get_outputs(train_x1, train_x2, train_x3)\r\n",
        "          GCCA_obj = GCCA(self.out_size, method=\"gcca\")\r\n",
        "          GCCA_obj.fit(outputs[0], outputs[1], outputs[2],params=None) #function from cca-zoo\r\n",
        "\r\n",
        "          loss = self.test(test_x1, test_x2, test_x3)\r\n",
        "      print(\"Fitted Model to Data\")"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9N9qOflxBnN"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25P0fh3xHZR"
      },
      "source": [
        "#Features for the model\r\n",
        "X = data.iloc[:,1:21]"
      ],
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r80V3_W0p7_9"
      },
      "source": [
        "# converting to tensor\r\n",
        "X = torch.from_numpy(X.to_numpy())"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvtx0SCI8iJu"
      },
      "source": [
        "#Splitting views in testing and training set\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iurqidHEqKuS"
      },
      "source": [
        "#Creating different views\r\n",
        "X1_train = X_train[0:2125][0:7]\r\n",
        "X2_train = X_train[0:2125][7:14]\r\n",
        "X3_train = X_train[0:2125][14:21]\r\n",
        "X1_test = X_test[0:2125][0:7]\r\n",
        "X2_test = X_test[0:2125][7:14]\r\n",
        "X3_test = X_test[0:2125][14:21]"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td6EXg7BKzNi"
      },
      "source": [
        "X1_train =torch.transpose(X1_train, 0, 1).float()\r\n",
        "X2_train =torch.transpose(X2_train, 0, 1).float()\r\n",
        "X3_train =torch.transpose(X3_train, 0, 1).float()\r\n",
        "X1_test =torch.transpose(X1_test, 0, 1).float()\r\n",
        "X2_test =torch.transpose(X2_test, 0, 1).float()\r\n",
        "X3_test =torch.transpose(X3_test, 0, 1).float()"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLxRCCL4L0mM"
      },
      "source": [
        "## Applying DGCCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC7u0FmhL-Tm",
        "outputId": "2b31414d-e427-4148-c159-16877ba8f39f"
      },
      "source": [
        "in_size_X1 = 7\r\n",
        "in_size_X2 = 7\r\n",
        "in_size_X3 = 7\r\n",
        "out_size = 2\r\n",
        "\r\n",
        "layer_sizes1 = [in_size_X1, 50, 50, out_size]\r\n",
        "layer_sizes2 = [in_size_X1, 50, 50, out_size]\r\n",
        "layer_sizes3 = [in_size_X1, 50, 50, out_size]\r\n",
        "\r\n",
        "model = DGCCA_architecture(layer_sizes1, layer_sizes2, layer_sizes3, \"sigmoid\")\r\n",
        "\r\n",
        "learning_rate = 1e-3\r\n",
        "epoch_num = 100\r\n",
        "batch_size = 80\r\n",
        "reg_par = 1e-5\r\n",
        "\r\n",
        "#DGCCA(self, architecture, learning_rate, epoch_num, batch_size, reg_par, out_size:int)\r\n",
        "algo = DGCCA(model, learning_rate, epoch_num, batch_size, reg_par, out_size)\r\n",
        "algo.fit(X1_train, X2_train, X3_train, X1_test, X2_test, X3_test)"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "more than 2 views therefore switched to generalized\n",
            "Fitted Model to Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_JlDz30T32m"
      },
      "source": [
        "loss, outputs = algo.test(torch.cat([X1_train, X1_test], dim=0), torch.cat([X2_train, X2_test], dim=0),torch.cat([X3_train, X3_test], dim=0))"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtSMTnRYTeK8"
      },
      "source": [
        "#Combining views"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXXiGd5v_RUE"
      },
      "source": [
        "## Creating ML Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agG4y4f2LirP"
      },
      "source": [
        "1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHF5B2scTM2N"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "ZQ_qVkVuLiHq",
        "outputId": "33826068-aa09-41a2-9eb5-f0f7f39e85a5"
      },
      "source": [
        "# lg_model = LogisticRegression()\r\n",
        "# lg_model.fit(X1_train, Y_train[0:3000][0:7])"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-393-2a8f55052670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1345\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 7]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VEcnhIN_1Za"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "**Conclusion** - \r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}